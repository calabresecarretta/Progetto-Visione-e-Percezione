{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f6d7f4-22e6-4706-b2ba-c795d11a27c6",
   "metadata": {},
   "source": [
    "1 - INSTALLAZIONE DELLE LIBRERIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa41da8-d74a-45fa-8bfa-439500ef2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (1.26.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: tensorflow-examples in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (0.1726271589.405268087897220913579094874191340194901890794504)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-examples) (2.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-examples) (1.16.0)\n",
      "Requirement already satisfied: numpy==1.26.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pycocotools) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pycocotools) (1.26.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (3.4)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: pyntcloud in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pyntcloud) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pyntcloud) (1.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pyntcloud) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pandas->pyntcloud) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pandas->pyntcloud) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from pandas->pyntcloud) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pyntcloud) (1.16.0)\n",
      "Requirement already satisfied: torch in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (3.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from torch) (73.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-hub in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-hub) (1.26.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-hub) (4.25.4)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (73.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tesisti\\anaconda3\\envs\\progetto2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras\n",
    "!pip install -q tensorflow_datasets\n",
    "!pip install -U tensorflow\n",
    "!pip install tensorflow-examples\n",
    "!pip install numpy==1.26.0\n",
    "!pip install pycocotools\n",
    "!pip install scikit-image\n",
    "!pip install pyntcloud\n",
    "!pip install torch\n",
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad3f26-9d9a-4a76-8505-77307f380c1f",
   "metadata": {},
   "source": [
    "2 - IMPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9e3122-4607-4295-82bf-8eff3c0cbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import cv2  \n",
    "import os\n",
    "import ijson\n",
    "import json\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import disk\n",
    "import plotly.graph_objs as go\n",
    "import tarfile\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "from tkinter import Tk, filedialog\n",
    "from keras.saving import register_keras_serializable\n",
    "import random\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fb832-0b23-447b-bb9b-4a572f7bf761",
   "metadata": {},
   "source": [
    "3 - DIRECTORY DEL PROGETTO DA SOSTITUIRE CON LA PROPRIA CARTELLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa6baa8-78b2-40a2-9edb-d8ad5b1500e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIRECTORY DEL PROGETTO DA SOSTITUIRE \n",
    "project_dir = 'C:/Users/Tesisti/Desktop/CalabreseCarretta/Progetto'\n",
    "#VARIABILE PER ESEGUIRE L'ADDESTRAMENTO\n",
    "addestramento = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d6f2c-a536-4b44-95e9-d636b102aeee",
   "metadata": {},
   "source": [
    "4 - DOWNLOAD DEL DATASET DI TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335d3eaa-8f0f-4f2e-bd7d-b2e8dc728376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il dataset esiste già nella cartella C:/Users/Tesisti/Desktop/CalabreseCarretta/Progetto\\COCOdataset2017. Saltando il download e l'estrazione.\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract(url, download_dir, extract_to=None):\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Scarica il file se non esiste già\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Scaricando {filename}...\")\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "        print(f\"Scaricato {filename} in {file_path}\")\n",
    "    else:\n",
    "        print(f\"{filename} esiste già, non è necessario scaricare.\")\n",
    "\n",
    "    # Estrai il file ZIP solo se necessario\n",
    "    if file_path.endswith(\".zip\") and extract_to:\n",
    "        # Verifica se la cartella è vuota\n",
    "        if not os.path.exists(extract_to):\n",
    "            if not os.path.exists(extract_to):\n",
    "                os.makedirs(extract_to)  # Crea la directory di estrazione\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                print(f\"Estrazione di {filename} in {extract_to}...\")\n",
    "                # Estrai ogni file nella directory di destinazione senza creare sottocartelle duplicate\n",
    "                for member in zip_ref.namelist():\n",
    "                    member_path = os.path.join(extract_to, os.path.basename(member))\n",
    "                    if os.path.basename(member):  # Ignora eventuali directory vuote\n",
    "                        with open(member_path, \"wb\") as output_file:\n",
    "                            output_file.write(zip_ref.read(member))\n",
    "                print(f\"Estrazione completata.\")\n",
    "        else:\n",
    "            print(f\"I file in {extract_to} esistono già. Saltando l'estrazione.\")\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# Percorso di salvataggio\n",
    "train_dataset_dir = os.path.join(project_dir, 'COCOdataset2017')\n",
    "images_dir = os.path.join(train_dataset_dir, 'images')\n",
    "annotations_dir = os.path.join(train_dataset_dir, 'annotations')\n",
    "\n",
    "train_images_dir = os.path.join(images_dir, 'train2017')\n",
    "val_images_dir = os.path.join(images_dir, 'val2017')\n",
    "test_images_dir = os.path.join(images_dir, 'test')\n",
    "# Verifica se il dataset è già presente\n",
    "if not os.path.exists(train_dataset_dir):\n",
    "    # URL per scaricare i file\n",
    "    urls = {\n",
    "        \"train_images\": \"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "        \"val_images\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "        \"annotations\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "    }\n",
    "\n",
    "    # Scarica le immagini di training\n",
    "    \n",
    "    download_and_extract(urls['train_images'], train_dataset_dir, images_dir)\n",
    "\n",
    "    # Scarica le immagini di validazione (che verranno usate come test)\n",
    "    \n",
    "    download_and_extract(urls['val_images'], train_dataset_dir, images_dir)\n",
    "\n",
    "    # Rinominare la cartella val2017 in test\n",
    "    \n",
    "    if os.path.exists(val_images_dir):\n",
    "        os.rename(val_images_dir, test_images_dir)\n",
    "        print(f\"Cartella {val_images_dir} rinominata in {test_images_dir}.\")\n",
    "\n",
    "    # Creazione del dataset di validazione (20% delle immagini di train)\n",
    "    val_images_dir = os.path.join(images_dir, 'val2017')\n",
    "    if not os.path.exists(val_images_dir):\n",
    "        os.makedirs(val_images_dir)\n",
    "\n",
    "    train_images = os.listdir(train_images_dir)\n",
    "    random.shuffle(train_images)\n",
    "    val_split_size = int(0.2 * len(train_images))\n",
    "\n",
    "    # Sposta il 20% delle immagini di train nella cartella val\n",
    "    for image in train_images[:val_split_size]:\n",
    "        shutil.move(\n",
    "            os.path.join(train_images_dir, image),\n",
    "            os.path.join(val_images_dir, image)\n",
    "        )\n",
    "    print(f\"Creato dataset di validazione in {val_images_dir} con {val_split_size} immagini.\")\n",
    "\n",
    "    # Scarica le annotazioni\n",
    "    download_and_extract(urls['annotations'], train_dataset_dir, train_dataset_dir)\n",
    "\n",
    "    # Rinomina ed organizza le annotazioni\n",
    "    annotations_zip_dir = os.path.join(train_dataset_dir, 'annotations')\n",
    "    annotations_files = os.listdir(annotations_zip_dir)\n",
    "\n",
    "    # Sposta i file .json nella cartella 'annotations'\n",
    "    for file_name in annotations_files:\n",
    "        if file_name.endswith('.json'):\n",
    "            os.rename(\n",
    "                os.path.join(annotations_zip_dir, file_name),\n",
    "                os.path.join(annotations_dir, file_name)\n",
    "            )\n",
    "\n",
    "    print(\"Scaricamento e organizzazione del dataset COCO 2017 completati!\")\n",
    "else:\n",
    "    print(f\"Il dataset esiste già nella cartella {train_dataset_dir}. Saltando il download e l'estrazione.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bce64-15a3-4fd5-b4a8-740afacf93f5",
   "metadata": {},
   "source": [
    "5 - DEFINIZIONE DELLE FUNZIONI PER CARICARE IMMAGINI E MASCHERE NEI DATASET TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97a0633-d7b5-4a0b-b474-0c2b67429949",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 128\n",
    "\n",
    "def get_image_id_from_path(image_path, coco):\n",
    "    \"\"\" Cerca l'ID dell'immagine nel dataset COCO basato sul nome del file \"\"\"\n",
    "    file_name = os.path.basename(image_path)\n",
    "    \n",
    "    # Ottieni tutte le immagini dal dataset COCO\n",
    "    img_info_list = coco.loadImgs(coco.getImgIds())\n",
    "    \n",
    "    # Cerca l'ID immagine corrispondente al nome del file\n",
    "    for img_info in img_info_list:\n",
    "        if img_info['file_name'] == file_name:\n",
    "            return img_info['id']\n",
    "    \n",
    "    # Se l'immagine non è stata trovata, solleva un'eccezione\n",
    "    raise ValueError(f\"ID immagine non trovato per il file: {file_name}\")\n",
    "\n",
    "def create_mask(image_id, coco):\n",
    "    annotation_ids = coco.getAnnIds(imgIds=image_id, iscrowd=False)\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    #print(f\"Trovate {len(annotations)} annotazioni per l'immagine {image_id}\")\n",
    "    \n",
    "    mask = np.zeros((dim, dim), dtype=np.uint8)\n",
    "    for annotation in annotations:\n",
    "        annotation_mask = coco.annToMask(annotation)\n",
    "        resized_mask = cv2.resize(annotation_mask, (dim, dim), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = np.maximum(mask, resized_mask)\n",
    "    return mask\n",
    "\n",
    "def load_image(image_path):\n",
    "    # Carica e decodifica l'immagine\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    # Ridimensiona l'immagine a dimxdim\n",
    "    image = tf.image.resize(image, [dim, dim])\n",
    "    \n",
    "    # Normalizza l'immagine nel range [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_image_with_mask(image_path, coco_key):\n",
    "    \"\"\"Carica l'immagine e genera la maschera corrispondente.\"\"\"\n",
    "    # Converti il tensore in una stringa se necessario\n",
    "    image_path_str = image_path.numpy().decode('utf-8') if hasattr(image_path, 'numpy') else image_path\n",
    "    coco_key_str = coco_key.numpy().decode('utf-8') if hasattr(coco_key, 'numpy') else coco_key\n",
    "\n",
    "    # Controlla se il file esiste\n",
    "    if not os.path.exists(image_path_str):\n",
    "        print(f\"Immagine non trovata per il file: {image_path_str}\")\n",
    "        empty_image = tf.zeros((dim, dim, 3), dtype=tf.float32)\n",
    "        empty_mask = tf.zeros((dim, dim, 1), dtype=tf.float32)\n",
    "        return empty_image, empty_mask\n",
    "\n",
    "    try:\n",
    "        # Carica l'immagine\n",
    "        image = load_image(image_path_str)\n",
    "        image_id = get_image_id_from_path(image_path_str, coco_dict[coco_key_str])\n",
    "\n",
    "        # Crea la maschera associata\n",
    "        mask = create_mask(image_id, coco_dict[coco_key_str])\n",
    "\n",
    "        # Converti la maschera in un tensore di TensorFlow\n",
    "        mask = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)  # Aggiungi una dimensione per renderla compatibile con (dim, dim, 1)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il caricamento di immagine o maschera: {e}\")\n",
    "        empty_image = tf.zeros((dim, dim, 3), dtype=tf.float32)\n",
    "        empty_mask = tf.zeros((dim, dim, 1), dtype=tf.float32)\n",
    "        return empty_image, empty_mask\n",
    "\n",
    "def load_image_wrapper(image_path_tensor, coco_key_tensor):\n",
    "    \"\"\"Wrapper per usare tf.py_function nella pipeline TensorFlow.\"\"\"\n",
    "    image, mask = tf.py_function(func=load_image_with_mask,\n",
    "                                 inp=[image_path_tensor, coco_key_tensor],\n",
    "                                 Tout=[tf.float32, tf.float32])\n",
    "    \n",
    "    # Definisci le dimensioni e le forme per TensorFlow\n",
    "    image.set_shape([dim, dim, 3])\n",
    "    mask.set_shape([dim, dim, 1])\n",
    "    return image, mask\n",
    "\n",
    "# Definizione del livello di data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    ])\n",
    "# Funzione di augmentazione che applica le stesse trasformazioni\n",
    "def augment_image_and_mask(image, mask):\n",
    "    # Concatenare immagine e maschera per applicare la stessa trasformazione\n",
    "    concatenated = tf.concat([image, mask], axis=-1)\n",
    "        \n",
    "    # Applicare data augmentation su immagine + maschera concatenate\n",
    "    augmented = data_augmentation(concatenated)\n",
    "        \n",
    "    # Separare immagine e maschera\n",
    "    augmented_image = augmented[..., :-1]  # Canali immagine\n",
    "    augmented_mask = augmented[..., -1:]  # Canale maschera (interpolazione nearest)\n",
    "        \n",
    "    return augmented_image, augmented_mask\n",
    "    \n",
    "# Applicare l'augmentazione al dataset\n",
    "def apply_augmentation_to_dataset(dataset):\n",
    "    return dataset.map(lambda image, mask: augment_image_and_mask(image, mask),\n",
    "                           num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c16d45-bdef-4d12-b066-133e2e25d25f",
   "metadata": {},
   "source": [
    "6 - DEFINIZIONI FUNZIONI PER OTTENERE UNA PARTE DEL DATASET E PER PREPROCESSARE IL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cc129f-3824-44f8-8abd-4eb15bdd36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni per ottenere un sottoinsieme del dataset e preprocessarlo\n",
    "def get_small_dataset(dataset, fraction = 0.1):\n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "    small_dataset_size = int(dataset_size * fraction)\n",
    "    return dataset.take(small_dataset_size)\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    def preprocess(x, y=None):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        if y is not None:  # Se y è presente, preprocessiamo anche la maschera\n",
    "            y = tf.cast(y, tf.float32)\n",
    "            return x, y\n",
    "        else:\n",
    "            return x  # Se y non è presente, restituiamo solo x\n",
    "\n",
    "    return dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2b39c-30d5-48bb-aa7b-392a03632d9b",
   "metadata": {},
   "source": [
    "7 - CREAZIONI DATASET TENSORFLOW TRAIN, VAL E TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41607c39-ddc0-4056-ae5d-abdedd4af24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=27.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_annotation_path = os.path.join(train_dataset_dir, 'annotations', 'instances_train2017.json')\n",
    "# Caricare annotazioni COCO per il set di addestramento\n",
    "annotation_coco = COCO(coco_annotation_path)\n",
    "\n",
    "# Dizionario per memorizzare gli oggetti COCO\n",
    "coco_dict = {'annotation': annotation_coco}\n",
    "\n",
    "# Directory delle immagini\n",
    "train_images_dir = os.path.join(train_dataset_dir, 'images', 'train2017')\n",
    "val_images_dir = os.path.join(train_dataset_dir, 'images', 'val2017')\n",
    "\n",
    "# Verifica i file nelle cartelle\n",
    "train_image_paths = [os.path.join(train_images_dir, fname) for fname in os.listdir(train_images_dir) if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "val_image_paths = [os.path.join(val_images_dir, fname) for fname in os.listdir(val_images_dir) if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Creazione dei dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, ['annotation'] * len(train_image_paths)))\n",
    "train_dataset = train_dataset.map(lambda x, y: load_image_wrapper(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, ['annotation'] * len(val_image_paths)))\n",
    "val_dataset = val_dataset.map(lambda x, y: load_image_wrapper(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Applica batching e prefetching\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Esegui l'addestramento su un sottoinsieme ridotto del dataset\n",
    "train_dataset = preprocess_dataset(train_dataset)\n",
    "val_dataset = preprocess_dataset(val_dataset)\n",
    "\n",
    "small_train_dataset = preprocess_dataset(get_small_dataset(train_dataset))\n",
    "small_val_dataset = preprocess_dataset(get_small_dataset(val_dataset))\n",
    "\n",
    "test_image_paths = [os.path.join(test_images_dir, fname) for fname in os.listdir(test_images_dir) if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_image_paths)\n",
    "test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = preprocess_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c16dc3-f387-4abb-9c47-4b31ef897922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CANCELLARE LA CELLA\n",
    "small_train_dataset = preprocess_dataset(get_small_dataset(train_dataset))\n",
    "small_val_dataset = preprocess_dataset(get_small_dataset(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34d750-c75b-4277-8129-b868eaa00eee",
   "metadata": {},
   "source": [
    "8 - DEFINIZIONE DEL MODELLO CON VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3472f097-ce5d-4097-a22f-e7fe8c1edc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocco di attenzione\n",
    "\n",
    "def attention_block_with_se(x, g, inter_channel):\n",
    "    theta_x = layers.Conv2D(inter_channel, 1)(x)\n",
    "    phi_g = layers.Conv2D(inter_channel, 1)(g)\n",
    "    concat_xg = layers.add([theta_x, phi_g])\n",
    "    relu_xg = layers.Activation('relu')(concat_xg)\n",
    "    psi = layers.Conv2D(1, 1, activation='sigmoid')(relu_xg)\n",
    "\n",
    "    # Squeeze-and-Excitation block\n",
    "    se_shape = (1, 1, x.shape[-1])\n",
    "    se = layers.GlobalAveragePooling2D()(x)\n",
    "    se = layers.Reshape(se_shape)(se)\n",
    "    se = layers.Dense(inter_channel // 2, activation='relu')(se)\n",
    "    se = layers.Dense(x.shape[-1], activation='sigmoid')(se)\n",
    "    x_se = layers.multiply([x, se])\n",
    "\n",
    "    return layers.multiply([x_se, psi])\n",
    "\n",
    "\n",
    "def create_unet_model_with_vgg16(input_shape=(dim, dim, 3)):\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    \n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    conv1 = vgg16.get_layer('block1_conv2')(vgg16.get_layer('block1_conv1')(inputs))\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    pool1 = vgg16.get_layer('block1_pool')(conv1)\n",
    "\n",
    "    conv2 = vgg16.get_layer('block2_conv2')(vgg16.get_layer('block2_conv1')(pool1))\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    pool2 = vgg16.get_layer('block2_pool')(conv2)\n",
    "\n",
    "    conv3 = vgg16.get_layer('block3_conv3')(vgg16.get_layer('block3_conv2')(vgg16.get_layer('block3_conv1')(pool2)))\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    pool3 = vgg16.get_layer('block3_pool')(conv3)\n",
    "\n",
    "    conv4 = vgg16.get_layer('block4_conv3')(vgg16.get_layer('block4_conv2')(vgg16.get_layer('block4_conv1')(pool3)))\n",
    "    drop4 = layers.SpatialDropout2D(0.5)(conv4)\n",
    "    pool4 = vgg16.get_layer('block4_pool')(drop4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', dilation_rate=2, kernel_regularizer=regularizers.l2(0.0002))(pool4)\n",
    "    conv5 = layers.BatchNormalization()(conv5)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0002))(conv5)\n",
    "    conv5 = layers.BatchNormalization()(conv5)\n",
    "    drop5 = layers.SpatialDropout2D(0.5)(conv5)\n",
    "\n",
    "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = layers.concatenate([drop4, up6], axis=3)\n",
    "    conv6 = layers.DepthwiseConv2D(3, padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 1, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(conv6)\n",
    "    conv6 = layers.BatchNormalization()(conv6)\n",
    "    conv6 = layers.Dropout(0.4)(conv6)\n",
    "\n",
    "    attention6 = attention_block_with_se(conv6, up6, 512)\n",
    "\n",
    "    up7 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(attention6))\n",
    "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
    "    conv7 = layers.DepthwiseConv2D(3, padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(512, 1, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(conv7)\n",
    "    conv7 = layers.BatchNormalization()(conv7)\n",
    "    conv7 = layers.Dropout(0.4)(conv7)\n",
    "\n",
    "    attention7 = attention_block_with_se(conv7, up7, 512)\n",
    "\n",
    "    up8 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(attention7))\n",
    "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
    "    conv8 = layers.DepthwiseConv2D(3, padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(256, 1, activation='relu', kernel_regularizer=regularizers.l2(0.00005))(conv8)\n",
    "    conv8 = layers.BatchNormalization()(conv8)\n",
    "    conv8 = layers.Dropout(0.3)(conv8)\n",
    "\n",
    "    attention8 = attention_block_with_se(conv8, up8, 256)\n",
    "\n",
    "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(attention8))\n",
    "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
    "    conv9 = layers.DepthwiseConv2D(3, padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 1, activation='relu', kernel_regularizer=regularizers.l2(0.00005))(conv9)\n",
    "    conv9 = layers.BatchNormalization()(conv9)\n",
    "    conv9 = layers.Dropout(0.3)(conv9)\n",
    "\n",
    "    attention9 = attention_block_with_se(conv9, up9, 64)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(attention9)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cea70-a644-4e8b-b796-c75941947830",
   "metadata": {},
   "source": [
    "9 - DEFINIZIONE MODELLO CON RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db8ee60-7168-44e9-acc3-9a625dacfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class ResizeLayer(layers.Layer):\n",
    "    def __init__(self, target_height, target_width, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, size=(self.target_height, self.target_width), method='bilinear')\n",
    "\n",
    "@register_keras_serializable()\n",
    "class AdjustDimensionsLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdjustDimensionsLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_output, decoder_output = inputs\n",
    "        encoder_shape = tf.shape(encoder_output)\n",
    "        resized_decoder_output = tf.image.resize(\n",
    "            decoder_output, size=(encoder_shape[1], encoder_shape[2]), method='bilinear'\n",
    "        )\n",
    "        return encoder_output, resized_decoder_output\n",
    "\n",
    "def create_unet_model_with_resnet50(input_shape=(128, 128, 3)):\n",
    "    resnet50 = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in resnet50.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Estrarre feature intermedie da ResNet-50\n",
    "    x = resnet50.get_layer('conv1_relu')(resnet50.get_layer('conv1_conv')(inputs))\n",
    "    x = resnet50.get_layer('pool1_pool')(x)\n",
    "    conv1 = resnet50.get_layer('conv2_block3_out')(x)  # (None, 64, 64, 256)\n",
    "    conv2 = resnet50.get_layer('conv3_block4_out')(conv1)  # (None, 32, 32, 512)\n",
    "    conv3 = resnet50.get_layer('conv4_block6_out')(conv2)  # (None, 16, 16, 1024)\n",
    "    conv4 = resnet50.get_layer('conv5_block3_out')(conv3)  # (None, 8, 8, 2048)\n",
    "    drop4 = layers.SpatialDropout2D(0.5)(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = layers.Conv2D(1024, 2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(layers.UpSampling2D(size=(2, 2))(drop4))\n",
    "    conv3, up6 = AdjustDimensionsLayer()([conv3, up6])\n",
    "    merge6 = layers.concatenate([conv3, up6], axis=3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(merge6)\n",
    "    conv6 = layers.Dropout(0.4)(conv6)\n",
    "\n",
    "    up7 = layers.Conv2D(512, 2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(layers.UpSampling2D(size=(2, 2))(conv6))\n",
    "    conv2, up7 = AdjustDimensionsLayer()([conv2, up7])\n",
    "    merge7 = layers.concatenate([conv2, up7], axis=3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(merge7)\n",
    "    conv7 = layers.Dropout(0.4)(conv7)\n",
    "\n",
    "    up8 = layers.Conv2D(256, 2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(layers.UpSampling2D(size=(2, 2))(conv7))\n",
    "    conv1, up8 = AdjustDimensionsLayer()([conv1, up8])\n",
    "    merge8 = layers.concatenate([conv1, up8], axis=3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(merge8)\n",
    "    conv8 = layers.Dropout(0.3)(conv8)\n",
    "\n",
    "    up9 = layers.Conv2D(128, 2, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(layers.UpSampling2D(size=(2, 2))(conv8))\n",
    "    up9 = ResizeLayer(128, 128)(up9) if inputs.shape[1] != up9.shape[1] else up9\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.0001))(up9)\n",
    "    conv9 = layers.Dropout(0.3)(conv9)\n",
    "\n",
    "    # Ultimo layer per ottenere l'output di dimensione 128x128\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b741c-f0a6-4d92-a904-477f4556b44f",
   "metadata": {},
   "source": [
    "10 - DEFINIZIONE DELLE METRICHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4b1637-52e9-43ab-9c5a-dfd4f011d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione personalizzata per SSIM, IoU e F1 Score e psnr\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def iou_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)  # Arrotondamento a 0 o 1 per segmentazione binaria\n",
    "    intersection = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    union = tf.reduce_sum(tf.cast(y_true + y_pred - y_true * y_pred, tf.float32))\n",
    "    iou = (intersection + 1e-10) / (union + 1e-10)  # Evita divisioni per zero\n",
    "    return iou\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)  # Arrotondamento a 0 o 1 per segmentazione binaria\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    precision = intersection / (tf.reduce_sum(y_pred) + 1e-10)\n",
    "    recall = intersection / (tf.reduce_sum(y_true) + 1e-10)\n",
    "    f1 = (2 * precision * recall) / (precision + recall + 1e-10)  # Evita divisioni per zero\n",
    "    return f1\n",
    "\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d75f6b-b03b-4d05-93c4-038cb3f17cee",
   "metadata": {},
   "source": [
    "11 - CREAZIONE, COMPILAZIONE E SALVATAGGIO DEL MODELLO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a5b119-3f40-47d8-aa52-9c6d293d75bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tesisti\\anaconda3\\envs\\progetto2\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Percorsi in cui salvare o da cui caricare il modello\n",
    "model_dir = os.path.join(project_dir, 'Modello')\n",
    "model_resnet_path = os.path.join(model_dir, 'modello_resnet.keras')\n",
    "model_vgg_path = os.path.join(model_dir, 'modello_vgg.keras')\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice_loss = 1 - (2 * tf.reduce_sum(y_true * y_pred) + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
    "    return bce_loss + dice_loss\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def bce_dice_loss_with_alpha(alpha):\n",
    "    @keras.saving.register_keras_serializable()\n",
    "    def loss(y_true, y_pred):\n",
    "        bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        dice_loss = 1 - (2 * tf.reduce_sum(y_true * y_pred) + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
    "        return alpha * bce_loss + (1 - alpha) * dice_loss\n",
    "    return loss\n",
    "\n",
    "class DynamicAlphaCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_alpha=0.5, final_alpha=0.1, total_epochs=20):\n",
    "        super().__init__()\n",
    "        self.initial_alpha = initial_alpha\n",
    "        self.final_alpha = final_alpha\n",
    "        self.total_epochs = total_epochs\n",
    "        self.current_alpha = initial_alpha\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Aggiorna alpha in base all'epoca corrente\n",
    "        self.current_alpha = self.initial_alpha - ((self.initial_alpha - self.final_alpha) * (epoch / self.total_epochs))\n",
    "        print(f\"\\n[DynamicAlphaCallback] Epoch {epoch + 1}: Current alpha = {self.current_alpha:.4f}\")\n",
    "        # Aggiorna la loss nel modello\n",
    "        self.model.loss = bce_dice_loss_with_alpha(self.current_alpha)\n",
    "\n",
    "\n",
    "dynamic_alpha_callback = DynamicAlphaCallback(initial_alpha=0.5, final_alpha=0.1, total_epochs=20)\n",
    "\n",
    "#Compila il modello con un valore iniziale per alpha\n",
    "initial_alpha = 0.5\n",
    "\n",
    "def training(model, model_path, augmentazione=True):\n",
    "    \n",
    "    # Compilazione del modello con le metriche personalizzate\n",
    "    model.compile(\n",
    "        optimizer=AdamW(learning_rate=0.0001, weight_decay=1e-5),\n",
    "        loss=bce_dice_loss_with_alpha(initial_alpha),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Callback per Early Stopping e riduzione del learning rate\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                   patience=5, \n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',        \n",
    "        factor=0.5,               \n",
    "        patience=3,               \n",
    "        min_lr=1e-6                \n",
    "    )\n",
    "\n",
    "    if augmentazione:\n",
    "        small_train_dataset = apply_augmentation_to_dataset(small_train_dataset)\n",
    "    \n",
    "    # Addestramento del modello\n",
    "    history = model.fit(\n",
    "        small_train_dataset,\n",
    "        validation_data=small_val_dataset,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, reduce_lr, dynamic_alpha_callback]\n",
    "    )\n",
    "\n",
    "    # Estrazione delle metriche dalla history\n",
    "    history_dict = history.history\n",
    "    train_loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    # Salvare le metriche in un file JSON\n",
    "    metriche_history = os.path.join(os.path.dirname(model_path), 'metriche_history.json')\n",
    "    with open(metriche_history, 'w') as f:\n",
    "        json.dump({'train_loss': train_loss, 'val_loss': val_loss}, f)\n",
    "\n",
    "    # Salva il modello addestrato\n",
    "    model.save(model_path)\n",
    "\n",
    "\n",
    "if addestramento:\n",
    "    # Creazione del modello\n",
    "    model_vgg = create_unet_model_with_vgg16(input_shape=(dim, dim, 3))\n",
    "    model_resnet = create_unet_model_with_resnet50(input_shape=(dim, dim, 3))\n",
    "\n",
    "    training(model_vgg, model_vgg_path, augmentazione=True)\n",
    "    #training(model_resnet, model_resnet_path, augmentazione=False)\n",
    "       # Grafico dell'andamento di train_loss e val_loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "else: \n",
    "    # Caricamento del modello\n",
    "    model = keras.models.load_model(\n",
    "        model_vgg_path,\n",
    "        custom_objects={\n",
    "            #'bce_dice_loss_with_alpha': bce_dice_loss_with_alpha,  # Funzione di perdita principale\n",
    "            'bce_dice_loss': bce_dice_loss,                       # Versione semplice della funzione di perdita\n",
    "            'loss': bce_dice_loss_with_alpha(0.5),\n",
    "            'psnr_metric' : psnr_metric# Funzione `loss` con un valore predefinito di alpha\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # model = keras.models.load_model(model_resnet_path, custom_objects={'bce_dice_loss_with_alpha': bce_dice_loss_with_alpha, \n",
    "    #                                                                    'ResizeLayer' : ResizeLayer,\n",
    "    #                                                                     'bce_dice_loss' :bce_dice_loss ,\n",
    "    #                                                                     'loss': bce_dice_loss_with_alpha(0.5),\n",
    "    #                                                                     'AdjustDimensionsLayer' : AdjustDimensionsLayer,\n",
    "    #                                                                    'psnr_metric' : psnr_metric})\n",
    "    model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90359c8-db93-4429-85fd-d32a7468b0c9",
   "metadata": {},
   "source": [
    "TEST PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5a558-7031-4f77-9d22-7a2e9eac5193",
   "metadata": {},
   "source": [
    "12 - VALUTAZIONE MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc8922-b200-4d84-bc9c-17a618aae91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataset, save_path='metriche_tabella.png'):\n",
    " \n",
    "    # Inizializza liste per raccogliere i valori delle metriche\n",
    "    accuracy_values = []\n",
    "    iou_values = []\n",
    "    f1_values = []\n",
    "    ssim_values = []\n",
    "    psnr_values = []\n",
    "\n",
    "    # Itera su ogni batch nel dataset di test\n",
    "    for x, y_true in dataset:\n",
    "        y_pred = model.predict(x, verbose=0)  # Previsione del modello\n",
    "\n",
    "        # Calcola le metriche per ogni batch\n",
    "        batch_accuracy = tf.reduce_mean(tf.keras.metrics.binary_accuracy(y_true, y_pred)).numpy()\n",
    "        batch_iou = iou_metric(y_true, y_pred).numpy()  # Assumi che restituisca un valore scalare\n",
    "        batch_f1 = f1_score(y_true, y_pred).numpy()  # Assumi che restituisca un valore scalare\n",
    "        batch_ssim = ssim_metric(y_true, y_pred).numpy()  # Valore medio di SSIM\n",
    "        batch_psnr = psnr_metric(y_true, y_pred).numpy()  # Valore medio di PSNR\n",
    "\n",
    "        # Aggiunge i valori delle metriche alla lista\n",
    "        accuracy_values.append(batch_accuracy)\n",
    "        iou_values.append(batch_iou)\n",
    "        f1_values.append(batch_f1)\n",
    "        ssim_values.append(batch_ssim)\n",
    "        psnr_values.append(batch_psnr)\n",
    "\n",
    "    # Calcola media e massimo per ciascuna metrica\n",
    "    metrics_summary = {\n",
    "        'accuracy': {'mean': np.mean(accuracy_values), 'max': np.max(accuracy_values)},\n",
    "        'iou': {'mean': np.mean(iou_values), 'max': np.max(iou_values)},\n",
    "        'f1_score': {'mean': np.mean(f1_values), 'max': np.max(f1_values)},\n",
    "        'ssim': {'mean': np.mean(ssim_values), 'max': np.max(ssim_values)},\n",
    "        'psnr': {'mean': np.mean(psnr_values), 'max': np.max(psnr_values)},\n",
    "    }\n",
    "\n",
    "    # Creazione di una tabella con matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table_data = [\n",
    "        [\"Metric\", \"Mean\", \"Max\"],\n",
    "        [\"Accuracy\", f\"{metrics_summary['accuracy']['mean']:.4f}\", f\"{metrics_summary['accuracy']['max']:.4f}\"],\n",
    "        [\"IoU\", f\"{metrics_summary['iou']['mean']:.4f}\", f\"{metrics_summary['iou']['max']:.4f}\"],\n",
    "        [\"F1 Score\", f\"{metrics_summary['f1_score']['mean']:.4f}\", f\"{metrics_summary['f1_score']['max']:.4f}\"],\n",
    "        [\"SSIM\", f\"{metrics_summary['ssim']['mean']:.4f}\", f\"{metrics_summary['ssim']['max']:.4f}\"],\n",
    "        [\"PSNR\", f\"{metrics_summary['psnr']['mean']:.4f}\", f\"{metrics_summary['psnr']['max']:.4f}\"]\n",
    "    ]\n",
    "    table = ax.table(cellText=table_data, colLabels=None, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)\n",
    "\n",
    "    # Salva l'immagine\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    return metrics_summary\n",
    "\n",
    "metriche_tabella_train = os.path.join(model_dir, 'metriche_tabella_train.png')\n",
    "metriche_tabella_val = os.path.join(model_dir, 'metriche_tabella_val.png')\n",
    "metrics = evaluate_metrics(model, small_train_dataset, save_path=metriche_tabella_train)\n",
    "metrics = evaluate_metrics(model, small_val_dataset, save_path=metriche_tabella_val)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93077c79-62d1-427d-b714-20be496b5f81",
   "metadata": {},
   "source": [
    "13 - DEFINIZIONE FUNZIONI PER OTTENERE LA DEPTH MAP E LE POINT CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ae703-530a-4d38-a941-1cbffd15b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare il modello MiDaS v3\n",
    "def load_midas_model():\n",
    "    model_type = \"DPT_Large\"  # Usa DPT_Large per maggiore accuratezza\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "    midas.eval()\n",
    "    transform = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").dpt_transform\n",
    "    return midas, transform\n",
    "\n",
    "# Funzione per ottenere la mappa di profondità utilizzando MiDaS v3\n",
    "def get_depth_map(image, midas, transform):\n",
    "    img_np = (image.numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    if img_np.shape[-1] == 3:\n",
    "        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    input_tensor = transform(img_np).unsqueeze(0)\n",
    "    if input_tensor.dim() == 5:\n",
    "        input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        depth_map = midas(input_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "    depth_map_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255\n",
    "    depth_map_normalized = depth_map_normalized.astype(np.uint8)\n",
    "\n",
    "    depth_map_filtered = median(depth_map_normalized, disk(3))\n",
    "    depth_map_filtered = depth_map_filtered.astype(np.uint8)\n",
    "\n",
    "    return depth_map_filtered\n",
    "\n",
    "# Funzione per creare la nuvola di punti 3D usando la mappa di profondità\n",
    "def image_to_3d_point_cloud(depth_map, intrinsics):\n",
    "    height, width = depth_map.shape\n",
    "    y_indices, x_indices = np.indices((height, width))\n",
    "    z_values = depth_map[y_indices, x_indices]\n",
    "\n",
    "    f_x = intrinsics['f_x']\n",
    "    f_y = intrinsics['f_y']\n",
    "    c_x = intrinsics['c_x']\n",
    "    c_y = intrinsics['c_y']\n",
    "\n",
    "    X = (x_indices - c_x)\n",
    "    Y = (y_indices - c_y)\n",
    "    Z = z_values\n",
    "\n",
    "    point_cloud_3d = np.column_stack((X.flatten(), Y.flatten(), Z.flatten()))\n",
    "    return point_cloud_3d\n",
    "\n",
    "# Parametri intrinseci della fotocamera\n",
    "intrinsics = {\n",
    "    'f_x': dim,  # Lunghezza focale sull'asse X\n",
    "    'f_y': dim,  # Lunghezza focale sull'asse Y\n",
    "    'c_x': 64,   # Centro ottico sull'asse X\n",
    "    'c_y': 64    # Centro ottico sull'asse Y\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b6b4e-bfec-4a78-b5df-8e1387def636",
   "metadata": {},
   "source": [
    "14 - DEFINIZIONE FUNZIONE PER VISUALIZZARE IMMAGINE, MASCHERA ORIGINALE, MASCHERA PREDETTA, DEPTH MAP, POINT CLOUD E POINT CLOUD SEGMENTATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddaf241-c273-44ec-a6bf-15960b1eef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_predictions_with_depth(model, dataset, midas, transform, intrinsics, num_samples=3, max_points=100000, has_masks=True, output_dir='./output'):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "    dataset_iter = iter(dataset)\n",
    "    samples_shown = 0\n",
    "\n",
    "    print(\"Starting image processing and saving...\")\n",
    "\n",
    "    for batch in dataset_iter:\n",
    "        if samples_shown >= num_samples:\n",
    "            break\n",
    "\n",
    "        if has_masks:\n",
    "            images, masks = batch\n",
    "        else:\n",
    "            images = batch\n",
    "\n",
    "        for j in range(images.shape[0]):\n",
    "            if samples_shown >= num_samples:\n",
    "                break\n",
    "\n",
    "            image = images[j]\n",
    "            if has_masks:\n",
    "                mask = masks[j]\n",
    "\n",
    "            # Perform prediction\n",
    "            pred = model.predict(tf.expand_dims(image, axis=0))\n",
    "            binary_pred = (pred > 0.5).astype(np.uint8).squeeze()\n",
    "\n",
    "            # Get the depth map\n",
    "            depth_map = get_depth_map(image, midas, transform)\n",
    "\n",
    "            # Estrai la nuvola di punti 3D\n",
    "            point_cloud_3d = image_to_3d_point_cloud(depth_map, intrinsics)\n",
    "\n",
    "            # Visualize and save all in a single plot\n",
    "            try:\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                \n",
    "                # Original Image\n",
    "                plt.subplot(1, 4, 1)\n",
    "                plt.imshow((image.numpy() * 255).astype(\"uint8\"))\n",
    "                plt.title(\"Original Image\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                # Original Mask, if present\n",
    "                if has_masks:\n",
    "                    plt.subplot(1, 4, 2)\n",
    "                    plt.imshow((image.numpy() * 255).astype(\"uint8\"))\n",
    "                    plt.imshow(mask.numpy().squeeze(), cmap='jet', alpha=0.5)\n",
    "                    plt.title(\"Original Mask\")\n",
    "                    plt.axis(\"off\")\n",
    "\n",
    "                # Predicted Mask\n",
    "                plt.subplot(1, 4, 3)\n",
    "                plt.imshow((image.numpy() * 255).astype(\"uint8\"))\n",
    "                plt.imshow(binary_pred, cmap='jet', alpha=0.5)\n",
    "                plt.title(\"Predicted Mask\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                # Depth Map\n",
    "                plt.subplot(1, 4, 4)\n",
    "                plt.imshow(depth_map, cmap='gray')\n",
    "                plt.title(\"Depth Map\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                # Save combined figure\n",
    "                combined_path = f\"{output_dir}/image_{samples_shown}_combined.png\"\n",
    "                plt.savefig(combined_path)\n",
    "                print(f\"Combined image saved: {combined_path}\")\n",
    "                plt.show()\n",
    "\n",
    "                 # Visualizza e salva la nuvola di punti 3D non segmentata\n",
    "                fig_original = go.Figure(data=[go.Scatter3d(\n",
    "                    x=point_cloud_3d[:, 0],\n",
    "                    y=point_cloud_3d[:, 1],\n",
    "                    z=point_cloud_3d[:, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=point_cloud_3d[:, 2],\n",
    "                        colorscale='Jet',\n",
    "                        opacity=0.5\n",
    "                    )\n",
    "                )])\n",
    "                fig_original.update_layout(\n",
    "                    scene=dict(\n",
    "                        xaxis_title='X coordinates',\n",
    "                        yaxis_title='Y coordinates',\n",
    "                        zaxis_title='Depth (Z)'\n",
    "                    ),\n",
    "                    title=\"Interactive 3D Point Cloud (No Segmentation)\"\n",
    "                )\n",
    "                html_path = f\"{output_dir}/point_cloud_{samples_shown}_original.html\"\n",
    "                fig_original.write_html(html_path)\n",
    "                print(f\"Nuvola di punti originale salvata: {html_path}\")\n",
    "                fig_original.show()  # Mostra la nuvola non segmentata in Jupyter\n",
    "\n",
    "                # Ridimensiona la maschera predetta per corrispondere alla risoluzione della mappa di profondità\n",
    "                binary_pred_resized = cv2.resize(binary_pred, (depth_map.shape[1], depth_map.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                binary_pred_flat = binary_pred_resized.flatten()\n",
    "\n",
    "                # Colori: rosso per l'oggetto (maschera == 1), blu per il resto (maschera == 0)\n",
    "                colors = np.where(binary_pred_flat == 1, 'red', 'blue')\n",
    "\n",
    "                # Visualizza e salva la nuvola di punti 3D segmentata\n",
    "                fig_segmented = go.Figure(data=[go.Scatter3d(\n",
    "                    x=point_cloud_3d[:, 0],\n",
    "                    y=point_cloud_3d[:, 1],\n",
    "                    z=point_cloud_3d[:, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=colors,\n",
    "                        opacity=0.8\n",
    "                    )\n",
    "                )])\n",
    "\n",
    "                fig_segmented.update_layout(\n",
    "                    scene=dict(\n",
    "                        xaxis_title='X coordinates',\n",
    "                        yaxis_title='Y coordinates',\n",
    "                        zaxis_title='Depth (Z)'\n",
    "                    ),\n",
    "                    title=\"Interactive 3D Point Cloud with Object Coloring\"\n",
    "                )\n",
    "\n",
    "                # Salva la nuvola segmentata come HTML\n",
    "                html_segmented_path = f\"{output_dir}/point_cloud_{samples_shown}_segmented.html\"\n",
    "                fig_segmented.write_html(html_segmented_path)\n",
    "                print(f\"Nuvola di punti segmentata salvata: {html_segmented_path}\")\n",
    "                fig_segmented.show()  # Mostra la nuvola segmentata in Jupyter\n",
    "\n",
    "                # Increment sample count\n",
    "                samples_shown += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during saving and visualization: {e}\")\n",
    "\n",
    "            if samples_shown >= num_samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b103e5-826c-4da5-a34c-f6929481b21a",
   "metadata": {},
   "source": [
    "15 - VISUALIZZAZIONE RISULTATI TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1a328-d79c-4f70-9b8c-5d2c6f94eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modello MiDaS v3\n",
    "midas, transform = load_midas_model()\n",
    "\n",
    "# Esegui la visualizzazione con mappa di profondità e nuvola 3D\n",
    "visualize_and_save_predictions_with_depth(model, small_train_dataset, midas, transform, intrinsics, num_samples=25, max_points=100000, has_masks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ccb0b3-232c-42ab-b8b0-420a1e2c1720",
   "metadata": {},
   "source": [
    "16 - VISUALIZZAZIONE RISULTATI DATASET DI TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888cc2b0-8578-411a-a7fd-e4d84a007629",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_save_predictions_with_depth(model, test_dataset, midas, transform, intrinsics, num_samples=30, max_points=100000, has_masks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a44d0-1962-4bbf-8ccd-e4cc504560f3",
   "metadata": {},
   "source": [
    "17 TEST CON IMMAGINE SCELTA DA PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7e4f3-c29a-4e07-afcb-dfbd3be9f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per selezionare l'immagine dal PC\n",
    "def select_image():\n",
    "    # Usa un file dialog per scegliere un'immagine\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Nasconde la finestra principale di Tkinter\n",
    "    root.attributes(\"-topmost\", 1)  # Porta la finestra in primo piano\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.bmp\")])\n",
    "    root.destroy()\n",
    "    \n",
    "    if not file_path:\n",
    "        print(\"Nessun file selezionato.\")\n",
    "        return None\n",
    "\n",
    "    # Carica l'immagine usando la funzione load_image\n",
    "    return load_image(file_path)\n",
    "\n",
    "# Carica l'immagine\n",
    "image_tensor = select_image()\n",
    "\n",
    "if image_tensor is not None:\n",
    "    # Aggiungi la dimensione del batch\n",
    "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "if image_tensor is not None:\n",
    "    # Crea un dataset simulato con una singola immagine per compatibilità con la funzione\n",
    "    dataset = tf.data.Dataset.from_tensors(image_tensor)\n",
    "\n",
    "    # Chiama la funzione di visualizzazione con questo dataset a immagine singola\n",
    "    output_dir='./output'\n",
    "    visualize_and_save_predictions_with_depth(\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        midas=midas,\n",
    "        transform=transform,\n",
    "        intrinsics=intrinsics,\n",
    "        num_samples=1,  # Una singola immagine\n",
    "        max_points=100000, has_masks=False\n",
    "    )\n",
    "else:\n",
    "    print(\"Nessuna immagine è stata selezionata o caricata.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
